<?xml version="1.0" encoding="utf-8"?><?workdir /Users/Ruth/forks/docs-ng/dita/src/ag3/temp/pdf/oxygen_dita_temp/Tasks?><?workdir-uri file:/Users/Ruth/forks/docs-ng/dita/src/ag3/temp/pdf/oxygen_dita_temp/Tasks/?><?path2project ../?><topic xmlns:ditaarch="http://dita.oasis-open.org/architecture/2005/" xml:lang="en-us" id="topic8798" ditaarch:DITAArchVersion="1.2" domains="(topic hi-d)                             (topic ut-d)                             (topic indexing-d)                            (topic hazard-d)                            (topic abbrev-d)                            (topic pr-d)                             (topic sw-d)                            (topic ui-d)    " class="- topic/topic " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="topic:1;4:40">
 <title class="- topic/title " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="title:1;5:9">Data recovery from remote clusters</title>
 <shortdesc class="- topic/shortdesc " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="shortdesc:1;6:13">Data recovery from remote clusters requires an XDCR environment and 
  adequate amount of memory and disk space to support the workload and recovered data.</shortdesc>
 <body class="- topic/body " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="body:1;8:8">
  <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:1;9:6">If more nodes fail in a cluster than the number of replicas, data partitions in that cluster
   will no longer be available. For instance, if you have a four node cluster with one replica per
   node and two nodes fail, some data partitions will no longer be available. There are two
   solutions for this scenario:</p>
  <ul class="- topic/ul " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="ul:1;13:7">
   <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="li:1;14:8">Recover data from disk. If you plan on recovering from disk, you may not be able to do so
     if the disk completely fails.</li>
   <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="li:2;16:8">Recover partitions from a remote cluster. You can use this second option when you have
     XDCR set up to replicate data to the second cluster. The requirement for using
      <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="codeph:1;18:15">cbrecovery</codeph> is that you need to set up a second cluster that will contain
     backup data.</li>
  </ul>
  <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:2;21:6">The following shows a scenario where replica vBuckets are lost from a
   cluster due to multi-node failure:</p>
  
  <image href="../images/cb_rec_multi_failure.png" width="600" placement="inline" class="- topic/image " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="image:1;24:64"/>
  
  <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:3;26:6">Before you perform a recovery, make sure that your main cluster has an adequate amount of
   memory and disk space to support the workload as well as the data you recover. This means that
   even though you can recover data to a cluster with failed nodes, you should investigate what
   caused the node failures and also make sure your cluster has adequate capacity before you recover
   data. If you do add nodes be certain to rebalance only after you have </p>
  
  <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:4;32:6">When you use <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="codeph:2;32:27">cbrecovery</codeph> it compares the data partitions from a main cluster
   with a backup cluster, then sends missing data partitions detected. If it fails, once you
   successfully restart <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="codeph:3;34:33">cbrecovery</codeph>, it will do a delta between clusters again and
   determine any missing partitions since the failure then resume restoring these partitions.</p>
  <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:5;36:6"><b class="+ topic/ph hi-d/b " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="b:1;36:9">Failure Scenarios</b></p>
  <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:6;37:6">Imagine the following happens when you have a four node cluster with one replica. Each node has
   256 active and 256 replica vBuckets which total 1024 active and 1024 replica vBuckets:</p>
  <ol class="- topic/ol " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="ol:1;39:7">
   <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="li:3;40:8">When one node fails, some active and some replica vBuckets are no longer available in the
     cluster.</li>
   <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="li:4;42:8">After you fail over this node, the corresponding replica vBuckets on other nodes will be
     put into an active state. At this point you have a full set of active vBuckets and a partial
     set of replica vBuckets in the cluster.</li>
   <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="li:5;45:8">A second node fails. More active vBuckets will not be accessible.</li>
   <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="li:6;46:8">You fail over the second node. At this point any missing active vBuckets that do not have
     corresponding replica vBuckets will be lost.</li>
  </ol>
  <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:7;49:6">In this type of scenario you can use <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="codeph:4;49:51">cbrecovery</codeph> to get the missing vBuckets
   from your backup cluster. If you have multi-node failure on both your main and backup clusters
   you will experience data loss.</p>
  <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:8;52:6"><b class="+ topic/ph hi-d/b " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="b:2;52:9">Recovery Scenarios for cbrecovery</b></p>
  <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:9;53:6">The following describes some different cluster setups so that you can better understand whether
   or not this approach will work in your failure scenario:</p>
  <ul class="- topic/ul " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="ul:2;55:7">
   <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="li:7;56:8">Multiple Node Failure in Cluster. If multiple nodes fail in a cluster then some
     vBuckets may be unavailable. In this case if you have already setup XDCR with another cluster,
     you can recover those unavailable vBuckets from the other cluster.</li>
   <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="li:8;59:8">Bucket with Inadequate Replicas.</li>
  </ul>
  <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:10;61:6"><b class="+ topic/ph hi-d/b " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="b:3;61:9">Single Bucket</b>. In this case where we have only one bucket with zero replicas on all the
   nodes in a cluster. In this case when a node goes down in the cluster some of the partitions for
   that node will be unavailable. If we have XDCR set up for this cluster we can recover the missing
   partitions with <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="codeph:5;64:28">cbrecovery</codeph>.</p>
  <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:11;65:6"><b class="+ topic/ph hi-d/b " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="b:4;65:9">Multi-Bucket</b>. In this case, nodes in a cluster have multiple buckets and some buckets
   might have replicas and some do not. In the image below we have a cluster and all nodes have two
   buckets, Bucket1 and Bucket2. Bucket 1 has replicas but Bucket2 does not. In this case if one of
   the nodes goes down, since Bucket 1 has replicas, when we failover the node the replicas on other
   nodes will be activated. But for the bucket with no replicas some partitions will be unavailable
   and will require <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="codeph:6;70:29">cbrecovery</codeph> to recover data. In this same example if multiple
   nodes fail in the cluster, we need to perform vBucket recovery both buckets since both will have
   missing partitions.</p>
  
  <image href="../images/cbrecovery_diff_replicas.png" width="600" placement="inline" class="- topic/image " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="image:2;74:68">
   </image>
  
  <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:12;77:6"><b class="+ topic/ph hi-d/b " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="b:5;77:9">Handling the Recovery</b></p>
  <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:13;78:6">Should you encounter node failure and have unavailable vBuckets, you should follow this
   process:</p>
  <ol class="- topic/ol " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="ol:2;80:7">
   <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="li:9;81:8">For each failed node, Click Fail Over under the Server Nodes tab in Web Console. 
    <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:14;82:8">After you click Fail Over, under Web Console | Log tab you will see whether data is
     unavailable and which vBuckets are unavailable. If you do not have enough replicas for the
     number of failed over nodes, some vBuckets will no longer be available:</p>

      <image href="../images/post-failover-log-lost-data.png" width="600" placement="inline" class="- topic/image " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="image:3;86:75">
      </image>
   </li>

   <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="li:10;90:8">Add new functioning nodes to replace the failed nodes.
    <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:15;91:8">Do not rebalance after you add new nodes to the cluster. Typically you do this after adding
     nodes to a cluster, but in this scenario the rebalance will destroy information about the
     missing vBuckets and you cannot recover them.</p>

      <image href="../images/cb_recovery1b.png" width="600" placement="inline" class="- topic/image " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="image:4;95:61">
      </image>

    <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:16;98:8">In this example we have two nodes that failed in a three-node cluster and we add a new node
     10.3.3.61.</p>
    <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:17;100:8">If you are certain your cluster can easily handle the workload and recovered data, you may
     choose to skip this step.</p></li>
   
   <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="li:11;103:8">Run <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="codeph:7;103:20">cbrecovery</codeph> to recover data from your backup cluster. In the Server
     Panel, a Stop Recovery button appears.

      <image href="../images/cb_recovery2.png" width="600" placement="inline" class="- topic/image " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="image:5;106:60">
      </image>
    <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:18;108:8">After the recovery completes, this button disappears.</p>
   </li>
    
   <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="li:12;111:8">Rebalance your cluster.
    <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:19;112:8">Once the recovery is done, you can rebalance your cluster, which will recreate replica
     vBuckets and evenly redistribute them across the cluster.</p>

      <image href="../images/cbrecovery_3b.png" width="600" placement="inline" class="- topic/image " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="image:6;115:61">
      </image>
   </li>
  </ol>
  
  <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:20;120:6"><b class="+ topic/ph hi-d/b " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="b:6;120:9">Recovery ‘Dry-Run’</b></p>
  <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:21;121:6">Before you recover vBuckets, you may want to preview a list of buckets no longer available in
   the cluster. Use this command and options:</p>
  <codeblock xml:space="preserve" class="+ topic/pre pr-d/codeblock " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="codeblock:1;123:14">
   shell&gt; ./cbrecovery http://Administrator:password@10.3.3.72:8091 http://Administrator:password@10.3.3.61:8091 -n
</codeblock>
  <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:22;126:6">Here we provide administrative credentials for the node in the cluster as well as the option
    <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="codeph:8;127:13">-n</codeph>. This will return a list of vBuckets in the remote secondary cluster which
   are no longer in the your first cluster. If there are any unavailable buckets in the cluster with
   failed nodes, you see output as follows:</p>
  <codeblock xml:space="preserve" class="+ topic/pre pr-d/codeblock " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="codeblock:2;130:14">
   2013-04-29 18:16:54,384: MainThread Missing vbuckets to be recovered:[{"node": "ns_1@10.3.3.61",
"vbuckets": [513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526,, 528, 529,
530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,, 547, 548,
549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567,
568, 569, 570, 571, 572,....
</codeblock>
  <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:23;137:6">Where the <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="codeph:9;137:24">vbuckets</codeph> array contains all the vBuckets that are no longer
   available in the cluster. These are the bucket you can recover from the remotes cluster. To
   recover the vBuckets:</p>
  <codeblock xml:space="preserve" class="+ topic/pre pr-d/codeblock " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="codeblock:3;140:14">
shell&gt; ./cbrecovery http://Administrator:password@&lt;From_IP&gt;:8091 \
 http://Administrator:password@&lt;To_IP&gt;:8091 -B bucket_name
</codeblock>
  <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:24;144:6">You can run the command on either the cluster with unavailable vBuckets or on the remote
   cluster, as long as you provide the hostname, port, and credentials for remote cluster and the
   cluster with missing vBuckets in that order. If you do not provide the parameter
    <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="codeph:10;147:13">-B</codeph> the tool assumes you will recover unavailable vBuckets for the default
   bucket.</p>
  <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:25;149:6"><b class="+ topic/ph hi-d/b " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="b:7;149:9">Monitoring the Recovery Process</b></p>
  <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:26;150:6">You can monitor the progress of recovery under the Data Buckets tab of Couchbase Web
   Console:</p>
  <ol class="- topic/ol " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="ol:3;152:7">
   <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="li:13;153:8">Click on the Data Buckets tab.</li>
   <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="li:14;154:8">Select the data bucket you are recovering in the Data Buckets drop-down.</li>
   <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="li:15;155:8">Click on the Summary drop-down to see more details about this data bucket. You see an
     increased number in the <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="codeph:11;156:38">items</codeph> level during recovery:

      <image href="../images/monitor_cb_recovery.png" width="600" placement="inline" class="- topic/image " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="image:7;158:67"/>
   </li>

   <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="li:16;161:8">You can also see the number of active vBuckets increase as they are recovered until you
     reach 1024 vBuckets. Click on the vBucket Resources drop-down:

      <image href="../images/cbrec_monitor_vbucks.png" width="600" placement="inline" class="- topic/image " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="image:8;164:68">
      </image>

   <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:27;167:7">As this tool runs from the command line you can stop it at any time as you would any other
     command-line tool.</p>
   </li>
    <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="li:17;170:9">A <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="codeph:12;170:19">Stop Recovery</codeph> button appears in the Servers panels. If you click this
     button, you will stop the recovery process between clusters. Once the recovery process
     completes, this button will no longer appear and you will need to rebalance the cluster. If you
     are in Couchbase Web Console, you can also stop it in this panel:

      <image href="../images/stop_cbrecovery.png" width="600" placement="inline" class="- topic/image " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="image:9;175:63"/>
    </li>

   <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="li:18;178:8">After recovery completes, click on the Server Nodes tab then Rebalance to rebalance your
     cluster.</li>
  </ol>
  
  
  <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:28;183:6">When <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="codeph:13;183:19">cbrecovery</codeph> finishes it will output a report in the console:</p>
  <codeblock xml:space="preserve" class="+ topic/pre pr-d/codeblock " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="codeblock:4;184:14">
 Recovery :                Total |    Per sec
 batch    :                 0000 |       14.5
 byte     :                 0000 |      156.0
 msg      :                 0000 |       15.6
4 vbuckets recovered with elapsed time 10.90 seconds
</codeblock>
  
  <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="p:29;192:6">In this report <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="codeph:14;192:29">batch</codeph> is a group of internal operations performed by
    <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="codeph:15;193:13">cbrecovery</codeph>, <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="codeph:16;193:42">byte</codeph> indicates the total number of bytes recovered
   and <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="codeph:17;194:16">msg</codeph> is the number of documents recovered.</p>
 </body>
 <related-links class="- topic/related-links " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="related-links:1;196:17"><linkpool class="- topic/linkpool " xtrc="topicref:45;54:51" xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Admin.ditamap"><link class="- topic/link " mapclass="- map/topicref " type="topic" xtrc="topicref:34;42:43" xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Admin.ditamap" href="../Tasks/tasks-common.dita" role="parent"><?ditaot usertext?><linktext class="- topic/linktext "><?ditaot gentext?>Common administrative tasks</linktext></link></linkpool>
  <linklist class="- topic/linklist " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="linklist:1;197:13">
   <link href="tasks-nodeFailover.dita" class="- topic/link " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="link:1;198:50" type="topic"><?ditaot gentext?><linktext class="- topic/linktext ">Failing over nodes</linktext><?ditaot genshortdesc?><desc class="- topic/desc ">Failing over a node means that Couchbase Server removes the node from a cluster and     makes replicated data at other nodes available for client requests.</desc></link>
   <link href="../XDCR/xdcr-intro.dita" class="- topic/link " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="link:2;199:41" type="topic"><?ditaot gentext?><linktext class="- topic/linktext ">Cross Datacenter Replication (XDCR)</linktext></link>
   <link href="tasks-manage-xdcr.dita" class="- topic/link " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="link:3;200:49" type="topic"><?ditaot gentext?><linktext class="- topic/linktext ">Managing XDCR</linktext><?ditaot genshortdesc?><desc class="- topic/desc ">Cross datacenter replication (XDCR) provides an easy method of replicating data from one   cluster to another for disaster recovery as well as better data locality (getting data closer to   its users).</desc></link>
   <link href="tasks-rebalance.dita" class="- topic/link " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Tasks/tasks-dataRecovery.dita" xtrc="link:4;201:47" type="topic"><?ditaot gentext?><linktext class="- topic/linktext ">Rebalancing</linktext></link>
   </linklist>
 </related-links>
</topic>