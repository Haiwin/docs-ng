<?xml version="1.0" encoding="utf-8"?><?workdir /Users/Ruth/forks/docs-ng/dita/src/ag3/temp/pdf/ag3/Misc?><?workdir-uri file:/Users/Ruth/forks/docs-ng/dita/src/ag3/temp/pdf/ag3/Misc/?><?path2project ../?><topic xmlns:ditaarch="http://dita.oasis-open.org/architecture/2005/" xml:lang="en-us" id="topic21334" ditaarch:DITAArchVersion="1.2" domains="(topic hi-d)                             (topic ut-d)                             (topic indexing-d)                            (topic hazard-d)                            (topic abbrev-d)                            (topic pr-d)                             (topic sw-d)                            (topic ui-d)    " class="- topic/topic " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="topic:1;4:41">
   <title class="- topic/title " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="title:1;5:11">Incorrect or missing data (server issue)</title>
   <shortdesc class="- topic/shortdesc " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="shortdesc:1;6:15">Data missing in query response or it’s wrong (potentially due to server issues)</shortdesc>
   <body class="- topic/body " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="body:1;7:10">
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:1;8:10">Sometimes, especially between releases for development builds, it’s possible results are
         missing due to issues in some component of Couchbase Server. This section describes how to
         do some debugging to identify which components, or at least to identify which components
         are not at fault.</p>
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:2;12:10">Before proceeding, it needs to be mentioned that each vbucket is physically represented by
         a CouchDB database (generated by couchstore component) which corresponds to exactly 1 file
         in the filesystem, example from a development environment using 16 vbuckets only (for
         example simplicity), 4 nodes and without replicas enabled:</p>
      <codeblock xml:space="preserve" class="+ topic/pre pr-d/codeblock " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeblock:1;16:18"><codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:1;16:26">&gt; tree ns_server/couch/0/
ns_server/couch/0/
 ???
_replicator.couch.1
 ???
_users.couch.1
 ??? default
     ??? 0.couch.1
     ??? 1.couch.1
     ??? 2.couch.1
     ??? 3.couch.1
     ??? master.couch.1
     ??? stats.json

 1 directory, 8 files

&gt; tree ns_server/couch/1/
ns_server/couch/1/
 ???
_replicator.couch.1
 ???
_users.couch.1
 ??? default
     ??? 4.couch.1
     ??? 5.couch.1
     ??? 6.couch.1
     ??? 7.couch.1
     ??? master.couch.1
     ??? stats.json
     ??? stats.json.old

 1 directory, 9 files

&gt; tree ns_server/couch/2/
ns_server/couch/2/
 ???
_replicator.couch.1
 ???
_users.couch.1
 ??? default
     ??? 10.couch.1
     ??? 11.couch.1
     ??? 8.couch.1
     ??? 9.couch.1
     ??? master.couch.1
     ??? stats.json
     ??? stats.json.old

 1 directory, 9 files

&gt; tree ns_server/couch/3/
ns_server/couch/3/
 ???
_replicator.couch.1
 ???
_users.couch.1
 ??? default
     ??? 12.couch.1
     ??? 13.couch.1
     ??? 14.couch.1
     ??? 15.couch.1
     ??? master.couch.1
     ??? stats.json
     ??? stats.json.old

 1 directory, 9 files
</codeph></codeblock>
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:3;83:10">For this particular example, because there are <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:2;83:65">no replicas enabled</codeph> (ran
            <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:3;84:21">./cluster_connect -n 4 -r 0</codeph> ), each node only has database files for
         the vbuckets it’s responsible for (active vbuckets). The numeric suffix in each database
         filename, starts at 1 when the database file is created and it gets incremented, by 1,
         every time the vbucket is compacted. If replication is enabled, for example you ran
            <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:4;88:21">./cluster_connect -n 4 -r 1</codeph>, then each node will have vbucket database
         files for the vbuckets it’s responsible for (active vbuckets) and for some replica
         vbuckets, example:</p>
      <codeblock xml:space="preserve" class="+ topic/pre pr-d/codeblock " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeblock:2;91:18"><codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:5;91:26">&gt; tree ns_server/couch/0/

ns_server/couch/0/
 ???
_replicator.couch.1
 ???
_users.couch.1
 ??? default
     ??? 0.couch.1
     ??? 1.couch.1
     ??? 12.couch.1
     ??? 2.couch.1
     ??? 3.couch.1
     ??? 4.couch.1
     ??? 5.couch.1
     ??? 8.couch.1
     ??? master.couch.1
     ??? stats.json

 1 directory, 12 files

&gt; tree ns_server/couch/1/

ns_server/couch/1/
 ???
_replicator.couch.1
 ???
_users.couch.1
 ??? default
     ??? 0.couch.1
     ??? 1.couch.1
     ??? 13.couch.1
     ??? 4.couch.1
     ??? 5.couch.1
     ??? 6.couch.1
     ??? 7.couch.1
     ??? 9.couch.1
     ??? master.couch.1
     ??? stats.json

 1 directory, 12 files

&gt; tree ns_server/couch/2/

ns_server/couch/2/
 ???
_replicator.couch.1
 ???
_users.couch.1
 ??? default
     ??? 10.couch.1
     ??? 11.couch.1
     ??? 14.couch.1
     ??? 15.couch.1
     ??? 2.couch.1
     ??? 6.couch.1
     ??? 8.couch.1
     ??? 9.couch.1
     ??? master.couch.1
     ??? stats.json

 1 directory, 12 files

&gt; tree ns_server/couch/3/
ns_server/couch/3/
 ???
_replicator.couch.1
 ???
_users.couch.1
 ??? default
     ??? 10.couch.1
     ??? 11.couch.1
     ??? 12.couch.1
     ??? 13.couch.1
     ??? 14.couch.1
     ??? 15.couch.1
     ??? 3.couch.1
     ??? 7.couch.1
     ??? master.couch.1
     ??? stats.json

 1 directory, 12 files
</codeph></codeblock>
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:4;174:10">You can figure out which vbucket are active in each node, by querying the following
         URL:</p>
      <codeblock xml:space="preserve" class="+ topic/pre pr-d/codeblock " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeblock:3;176:18"><codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:6;176:26">&gt; curl -s http://localhost:8091/pools/default/buckets |
  json_xs
 [
    {
       "quota" :
{
          "rawRAM" : 268435456,
          "ram"
: 1073741824
       },
       "localRandomKeyUri" : "/pools/default/buckets/default/localRandomKey",
       "bucketCapabilitiesVer" : "",
       "authType"
: "sasl",
       "uuid" :
  "89dd5c64504f4a9414a2d3bcf9630d15",
       "replicaNumber" : 1,
       "vBucketServerMap" : {
          "vBucketMap" : [
             [
                0,
                1
             ],
             [
                0,
                1
             ],
             [
                0,
                2
             ],
             [
                0,
                3
             ],
             [
                1,
                0
             ],
             [
                1,
                0
             ],
             [
                1,
                2
             ],
             [
                1,
                3
             ],
             [
                2,
                0
             ],
             [
                2,
                1
             ],
             [
                2,
                3
             ],
             [
                2,
                3
             ],
             [
                3,
                0
             ],
             [
                3,
                1
             ],
             [
                3,
                2
             ],
             [
                3,
                2
             ]
          ],
          "numReplicas" : 1,
          "hashAlgorithm" : "CRC",
          "serverList" : [
             "192.168.1.81:12000",
             "192.168.1.82:12002",
             "192.168.1.83:12004",
             "192.168.1.84:12006"
          ]
       },

(....)
 ]
</codeph></codeblock>
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:5;273:10">The field to look at is named <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:7;273:48">vBucketServerMap</codeph>, and it contains two
         important sub-fields, named <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:8;274:46">vBucketMap</codeph> and <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:9;274:78">serverList</codeph>,
         which we use to find out which nodes are responsible for which vbuckets (active
         vbuckets).</p>
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:6;277:10">Looking at these 2 fields, we can do the following active and replica vbucket to node
         mapping:</p>
      <ul class="- topic/ul " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="ul:1;279:11">
         <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="li:1;280:14"><p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:7;280:17">vbuckets 0, 1, 2 and 3 are active at node 192.168.1.81:12000, and vbuckets 4, 5, 8
               and 12 are replicas at that same node</p></li>
         <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="li:2;282:14"><p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:8;282:17">vbuckets 4, 5, 6 and 7 are active at node 192.168.1.82:12002, and vbuckets 0, 1, 9
               and 13 are replicas at that same node</p></li>
         <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="li:3;284:14"><p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:9;284:17">vbuckets 8, 9, 10 and 11 are active at node 192.168.1.83:12004, and vbuckets 2, 6,
               14 and 15 are replicas at that same node</p></li>
         <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="li:4;286:14"><p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:10;286:17">vbuckets 12, 13, 14 and 15 are active at node 192.168.1.84:12006, and vbucket 3, 7,
               11 and 10</p></li>
      </ul>
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:11;289:10">the value of <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:10;289:31">vBucketMap</codeph> is an array of arrays of 2 elements. Each
         sub-array corresponds to a vbucket, so the first one is related to vbucket 0, second one to
         vbucket 1, etc, and the last one to vbucket 15. Each sub-array element is an index
         (starting at 0) into the <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:11;292:43">serverList</codeph> array. First element of each sub-array
         tells us which node (server) has the corresponding vbucket marked as active, while the
         second element tells us which server has this vbucket marked as replica.</p>
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:12;295:10">If the replication factor is greater than 1 (N &gt; 1), then each sub-array will have N + 1
         elements, where first one is always index of server/node that has that vbucket active and
         the remaining elements are the indexes of the servers having the first, second, third, etc
         replicas of that vbucket.</p>
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:13;299:10">After knowing which vbuckets are active in each node, we can use some tools such as
            <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:12;300:21">couch_dbinfo</codeph> and <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:13;300:55">couch_dbdump</codeph> to analyze active
         vbucket database files. Before looking at those tools, lets first know what database
         sequence numbers are.</p>
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:14;303:10">When a CouchDB database (remember, each corresponds to a vbucket) is created, its
         update_seq (update sequence number) is 0. When a document is created, updated or deleted,
         its current sequence number is incremented by 1. So all the following sequence of actions
         result in the final sequence number of 5:</p>
      <ol class="- topic/ol " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="ol:1;307:11">
         <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="li:5;308:14"><p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:15;308:17">Create document doc1, create document doc2, create document doc3, create document
               doc4, create document doc5</p></li>
         <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="li:6;310:14"><p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:16;310:17">Create document doc1, update document doc1, update document doc1, update document
               doc1, delete document doc1</p></li>
         <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="li:7;312:14"><p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:17;312:17">Create document doc1, delete document doc1, create document doc2, update document
               doc2, update document doc2</p></li>
         <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="li:8;314:14"><p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:18;314:17">Create document doc1, create document doc2, create document doc3, create document
               doc4, update document doc2</p></li>
         <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="li:9;316:14"><p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:19;316:17">etc…</p></li>
      </ol>
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:20;318:10">You can see the current update_seq of a vbucket database file, amongst other information,
         with the <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:14;319:27">couch_dbinfo</codeph> command line tool, example with vbucket 0, active in
         the first node:</p>
      <codeblock xml:space="preserve" class="+ topic/pre pr-d/codeblock " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeblock:4;321:18"><codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:15;321:26">&gt; ./install/bin/couch_dbinfo ns_server/couch/0/default/0.couch.1
 DB Info
  (ns_server/couch/0/default/0.couch.1)
    file format version: 10
    update_seq: 31250
    doc count: 31250
    deleted doc count: 0
    data size: 3.76 MB
    B-tree size: 1.66 MB
    total disk size: 5.48 MB
</codeph></codeblock>
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:21;332:10">After updating all the documents in that vbucket database, the update_seq doubled:</p>
      <codeblock xml:space="preserve" class="+ topic/pre pr-d/codeblock " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeblock:5;333:18"><codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:16;333:26">&gt; ./install/bin/couch_dbinfo ns_server/couch/0/default/0.couch.1
DB Info
 (ns_server/couch/0/default/0.couch.1)
   file format version: 10
   update_seq:00
   doc count: 31250
   deleted doc count: 0
   data size: 3.76 MB
   B-tree size: 1.75 MB
   total disk size: 10.50 MB
</codeph></codeblock>
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:22;344:10">An important detail, if not obvious, is that with each vbucket database sequence number one
         and only one document ID is associated to it. At any time, there’s only one update sequence
         number associated with a document ID, and it’s always the most recent. We can verify this
         with the <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:17;347:27">couch_dbdump</codeph> command line tool. Take the following example, where
         we only have 2 documents, document with ID doc1 and document with ID doc2:</p>
      <codeblock xml:space="preserve" class="+ topic/pre pr-d/codeblock " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeblock:6;349:18"><codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:18;349:26">&gt; ./install/bin/couch_dbdump ns_server/couch/0/default/0.couch.1
Doc seq: 1
     id: doc1
     rev: 1
     content_meta: 0
     cas: 130763975746, expiry: 0, flags: 0
     data: {"value": 1}
Total docs: 1
</codeph></codeblock>
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:23;358:10">On an empty vbucket 0 database, we created document with ID <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:19;358:78">doc1</codeph>, which
         has a JSON value of <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:20;359:38">{"value": 1}</codeph>. This document is now associated with
         update sequence number 1. Next we create another document, with ID *doc2* and JSON value
            <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:21;361:21">{"value": 2}</codeph>, and the output of <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:22;361:70">couch_dbdump</codeph> is:</p>
      <codeblock xml:space="preserve" class="+ topic/pre pr-d/codeblock " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeblock:7;362:18"><codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:23;362:26">&gt; ./install/bin/couch_dbdump ns_server/couch/0/default/0.couch.1
Doc seq: 1
     id: doc1
     rev: 1
     content_meta: 0
     cas: 130763975746, expiry: 0, flags: 0
     data: {"value": 1}
Doc seq: 2
     id: doc2
     rev: 1
     content_meta: 0
     cas: 176314689876, expiry: 0, flags: 0
     data: {"value": 2}
Total docs: 2
</codeph></codeblock>
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:24;377:10">Document <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:24;377:27">doc2</codeph> got associated to vbucket 0 database update sequence number
         2. Next, we update document <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:25;378:46">doc1</codeph> with a new JSON value of
            <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:26;379:21">{"value": 1111}</codeph>, and <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:27;379:59">couch_dbdump</codeph> tells us:</p>
      <codeblock xml:space="preserve" class="+ topic/pre pr-d/codeblock " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeblock:8;380:18"><codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:28;380:26">&gt; ./install/bin/couch_dbdump ns_server/couch/0/default/0.couch.1
Doc seq: 2
     id: doc2
     rev: 1
     content_meta: 0
     cas: 176314689876, expiry: 0, flags: 0
     data: {"value": 2}
Doc seq: 3
     id: doc1
     rev: 2
     content_meta: 0
     cas: 201537725466, expiry: 0, flags: 0
     data: {"value": 1111}

Total docs: 2
</codeph></codeblock>
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:25;396:10">So, document <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:29;396:31">doc1</codeph> is now associated with update sequence number 3. Note
         that it’s no longer associated with sequence number 1, because the update was the most
         recent operation against that document (remember, only 3 operations are possible: create,
         update or delete). The database no longer has a record for sequence number 1 as well. After
         this, we update document <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:30;400:43">doc2</codeph> with JSON value <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:31;400:81">{"value":
            2222}</codeph>, and we get the following output from <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:32;401:74">couch_dbdump</codeph> :</p>
      <codeblock xml:space="preserve" class="+ topic/pre pr-d/codeblock " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeblock:9;402:18"><codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:33;402:26">&gt; ./install/bin/couch_dbdump ns_server/couch/0/default/0.couch.1
Doc seq: 3
     id: doc1
     rev: 2
     content_meta: 0
     cas: 201537725466, expiry: 0, flags: 0
     data: {"value": 1111}
Doc seq: 4
     id: doc2
     rev: 2
     content_meta: 0
     cas: 213993873979, expiry: 0, flags:   0
     data: {"value": 2222}

Total docs: 2
</codeph></codeblock>
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:26;418:10">Document <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:34;418:27">doc2</codeph> is now associated with sequence number 4, and sequence
         number 2 no longer has a record in the database file. Finally we deleted document
            <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:35;420:21">doc1</codeph>, and then we get:</p>
      <codeblock xml:space="preserve" class="+ topic/pre pr-d/codeblock " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeblock:10;421:18"><codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:36;421:26">&gt; ./install/bin/couch_dbdump ns_server/couch/0/default/0.couch.1
Doc seq: 4
     id: doc2
     rev: 2
     content_meta: 0
     cas: 213993873979, expiry: 0, flags: 0
     data: {"value": 2222}
Doc seq: 5
     id: doc1
     rev: 3
     content_meta: 3
     cas: 201537725467, expiry: 0, flags: 0
     doc deleted
     could not read document body: document not found

Total docs: 2
</codeph></codeblock>
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:27;438:10">Note that document deletes don’t really delete documents from the database files, instead
         they flag the document has deleted and remove its JSON (or binary) value. Document
            <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:37;440:21">doc1</codeph> is now associated with sequence number 5 and the record for its
         previously associated sequence number 3, is removed from the vbucket 0 database file. This
         allows for example, indexes to know they have to delete all Key-Value pairs previously
         emitted by a map function for a document that was deleted - if there weren’t any update
         sequence number associated with the delete operation, indexes would have no way to know if
         documents were deleted or not.</p>
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:28;446:10">These details of sequence numbers and document operations are what allow indexes to be
         updated incrementally in Couchbase Server (and Apache CouchDB as well).</p>
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:29;448:10">In Couchbase Server, indexes store in their header (state) the last update_seq seen for
         each vbucket database. Put it simply, whenever an index build/update finishes, it stores in
         its header the last update_seq processed for each vbucket database. Vbucket databases have
         states too in indexes, and these states do not necessarily match the vbucket states in the
         server. For the goals of this wiki page, it only matters to mention that view requests with
            <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:38;453:21">stale=false</codeph> will be blocked only if the currently stored update_seq of
         any active vbucket in the index header is smaller than the current update_seq of the
         corresponding vbucket database - if this is true for at least one active vbucket, an index
         update is scheduled immediately (if not already running) and when it finishes it will
         unblock the request. Requests with <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:39;457:53">stale=false</codeph> will not be blocked if the
         update_seq of vbuckets in the index with other states (passive, cleanup, replica) are
         smaller than the current update_seq of the corresponding vbucket databases - the reason for
         this is that queries only see rows produced for documents that live in the active
         vbuckets.</p>
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:30;462:10">We can see that states of vbuckets in the index, and the update_seqs in the index, by
         querying the following URL (example for 16 vbuckets only, for the sake of simplicity):</p>
      <codeblock xml:space="preserve" class="+ topic/pre pr-d/codeblock " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeblock:11;464:18"><codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:40;464:26">&gt; curl -s 'http://localhost:9500/_set_view/default/_design/dev_test2/_info' | json_xs
{
   "unindexable_partitions" : {},
   "passive_partitions" : [],
   "compact_running" : false,
   "cleanup_partitions" : [],
   "replica_group_info" : {
      "unindexable_partitions" : {},
      "passive_partitions" : [
         4,
         5,
         8,
         12
      ],
      "compact_running" : false,
      "cleanup_partitions" : [],
      "active_partitions" : [],
      "pending_transition" : null,
      "db_set_message_queue_len" : 0,
      "out_of_sync_db_set_partitions" : false,
      "expected_partition_seqs" : {
         "8" :00,
         "4" :00,
         "12" :00,
         "5" :00
      },
      "updater_running" : false,
      "partition_seqs" : {
         "8" :00,
         "4" :00,
         "12" :00,
         "5" :00
      },
      "stats" : {
         "update_history" : [
            {
               "deleted_ids" : 0,
               "inserted_kvs" : 38382,
               "inserted_ids" : 12794,
               "deleted_kvs" : 38382,
               "cleanup_kv_count" : 0,
               "blocked_time" : 1.5e-05,
               "indexing_time" : 3.861918
            }
         ],
         "updater_cleanups" : 0,
         "compaction_history" : [
            {
               "cleanup_kv_count" : 0,
               "duration" : 1.955801
            },
            {
               "cleanup_kv_count" : 0,
               "duration" : 2.443478
            },
            {
               "cleanup_kv_count" : 0,
               "duration" : 4.956397
            },
            {
               "cleanup_kv_count" : 0,
               "duration" : 9.522231
            }
         ],
         "full_updates" : 1,
         "waiting_clients" : 0,
         "compactions" : 4,
         "cleanups" : 0,
         "partial_updates" : 0,
         "stopped_updates" : 0,
         "cleanup_history" : [],
         "cleanup_interruptions" : 0
      },
      "initial_build" : false,
      "update_seqs" : {
         "8" :00,
         "4" :00,
         "12" :00,
         "5" :00
      },
      "partition_seqs_up_to_date" : true,
      "updater_state" : "not_running",
      "data_size" : 5740951,
      "cleanup_running" : false,
      "signature" : "440b0b3ded9d68abb559d58b9fda3e0a",
      "max_number_partitions" : 16,
      "disk_size" : 5742779
   },
   "active_partitions" : [
      0,
      1,
      2,
      3
   ],
   "pending_transition" : null,
   "db_set_message_queue_len" : 0,
   "out_of_sync_db_set_partitions" : false,
   "replicas_on_transfer" : [],
   "expected_partition_seqs" : {
      "1" :00,
      "3" :00,
      "0" :00,
      "2" :00
   },
   "updater_running" : false,
   "partition_seqs" : {
      "1" :00,
      "3" :00,
      "0" :00,
      "2" :00
   },
   "stats" : {
      "update_history" : [],
      "updater_cleanups" : 0,
      "compaction_history" : [],
      "full_updates" : 0,
      "waiting_clients" : 0,
      "compactions" : 0,
      "cleanups" : 0,
      "partial_updates" : 0,
      "stopped_updates" : 0,
      "cleanup_history" : [],
      "cleanup_interruptions" : 0
   },
   "initial_build" :   false,
   "replica_partitions" : [
      4,
      5,
      8,
      12
   ],
   "update_seqs" : {
      "1" : 31250,
      "3" : 31250,
      "0" : 31250,
      "2" : 31250
   },
   "partition_seqs_up_to_date" : true,
   "updater_state" :   "not_running",
   "data_size" : 5717080,
   "cleanup_running" : false,
   "signature" :   "440b0b3ded9d68abb559d58b9fda3e0a",
   "max_number_partitions" : 16,
   "disk_size" : 5726395
}
</codeph></codeblock>
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:31;610:10">The output gives us several fields useful to diagnose issues in the server. The field
            <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:41;611:21">replica_group_info</codeph> can be ignored for the goals of this wiki (would
         only be useful during a failover), the information it contains is similar to the top level
         information, which is the one for the main/principal index, which is the one we care about
         during steady state and during rebalance.</p>
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:32;615:10">Some of the top level fields and their meaning:</p>
      <ul class="- topic/ul " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="ul:2;616:11">
         <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="li:10;617:14"><p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:33;617:17"><codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:42;617:25">active_partitions</codeph> - this is a list with the ID of all the vbuckets
               marked as active in the index.</p></li>
         <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="li:11;619:14"><p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:34;619:17"><codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:43;619:25">passive_partitions</codeph> - this is a list with the ID of all vbuckets
               marked as passive in the index.</p></li>
         <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="li:12;621:14"><p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:35;621:17"><codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:44;621:25">cleanup_partitions</codeph> - this is a list with the ID of all vBuckets
               marked as cleanup in the index.</p></li>
         <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="li:13;623:14"><p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:36;623:17"><codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:45;623:25">compact_running</codeph> - true if index compaction is ongoing, false
               otherwise.</p></li>
         <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="li:14;625:14"><p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:37;625:17"><codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:46;625:25">updater_running</codeph> - true if index build/update is ongoing, false
               otherwise.</p></li>
         <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="li:15;627:14"><p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:38;627:17"><codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:47;627:25">update_seqs</codeph> - this tells us what up to which vbucket database
               update_seqs the index reflects data, keys are vbucket IDs and values are update_seqs.
               The update_seqs here are always smaller or equal then the values in
                  <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:48;630:27">partition_seqs</codeph> and <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:49;630:63">expected_partition_seqs</codeph>. If
               the value of any update_seq here is smaller than the corresponding value in
                  <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:50;632:27">partition_seqs</codeph> or <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:51;632:62">expected_partition_seqs</codeph>, than
               it means the index is not up to date (it’s stale), and a subsequent query with
                  <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:52;634:27">stale=false</codeph> will be blocked and spawn an index update (if not
               already running).</p></li>
         <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="li:16;636:14"><p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:39;636:17"><codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:53;636:25">partition_seqs</codeph> - this tells us what are the current update_seqs for
               each vbucket database. If any update_seq value here is greater than the corresponding
               value in <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:54;638:33">update_seqs</codeph>, we can say the index is not up to date (it’s
               stale). See the description above for <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:55;639:62">update_seqs</codeph>.</p></li>
         <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="li:17;640:14"><p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:40;640:17"><codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:56;640:25">expected_partition_seqs</codeph> - this should normally tells us exactly the
               same as <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:57;641:32">partition_seqs</codeph> (see above). Index processes have an
               optimization where they monitor vbucket database updates and track their current
               update_seqs, so that when the index needs to know them, it doesn’t need to consult
               them from the databases (expensive, from a performance perspective). The update_seqs
               in this field are obtained by consulting each database file. If they don’t match the
               corresponding values in <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:58;646:48">partition_seqs</codeph>, then we can say there’s an
               issue in the view-engine.</p></li>
         <li class="- topic/li " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="li:18;648:14"><p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:41;648:17"><codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:59;648:25">unindexable_partitions</codeph> - this field should be non-empty only during
               rebalance. Vbuckets that are in this meta state “unindexable” means that index
               updates will ignore these vbuckets. Transitions to and from this state are used by
               ns_server for consistent views during rebalance. When not in rebalance, this field
               should always be empty, if not, then there’s a issue somewhere. The value for this
               field, when non-empty, is an object whose keys are vbucket IDs and values are
               update_seqs.</p></li>
      </ul>
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:42;656:10">Using the information given by this URL (remember, it’s on a per node basis), to check the
         vbucket states and indexed update_seqs, together with the tools
            <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:60;658:21">couch_dbinfo</codeph> and <codeph class="+ topic/ph pr-d/codeph " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="codeph:61;658:55">couch_dbdump</codeph> (against all active
         vbucket database files), one can debug where (which component) a problem is. For example,
         it’s useful to find if it’s the indexes that are not indexing latest
         data/updates/processing deletes, or if the memcached/ep-engine layer is not persisting
         data/updates to disk or if there’s some issue in couchstore (component which writes to
         database files) that causes it to not write data or write incorrect data to the database
         file.</p>
      <p class="- topic/p " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="p:43;665:10">An example where using these tools and the information from the URL
         /_set_view/bucketname/_design/ddocid/_info was very important to find which component was
         misbehaving. In
         this case Tommie was able to identify that the problem was in ep-engine.</p>
   </body>
   <related-links class="- topic/related-links " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="related-links:1;670:19"><linkpool class="- topic/linkpool " xtrc="topicref:137;156:55" xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Admin.ditamap"><link class="- topic/link " mapclass="- map/topicref " type="topic" xtrc="topicref:129;148:40" xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Admin.ditamap" href="../Misc/Trbl-intro.dita" role="parent"><?ditaot usertext?><linktext class="- topic/linktext "><?ditaot gentext?>Troubleshooting</linktext><?ditaot genshortdesc?><desc class="- topic/desc ">Troubleshooting covers general tips, common errors, log information, and other issues.</desc></link></linkpool>
      <linklist class="- topic/linklist " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="linklist:1;671:17">
         <link href="http://www.couchbase.com/issues/browse/MB-5534" scope="external" format="html" class="- topic/link " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="link:1;672:101"><?ditaot usertext?><linktext class="- topic/linktext " xtrf="/Users/Ruth/forks/docs-ng/dita/src/ag3/Misc/Trbl-datamissing-server.dita" xtrc="linktext:1;673:23">http://www.couchbase.com/issues/browse/MB–5534</linktext></link>
      </linklist>
   </related-links>
</topic>