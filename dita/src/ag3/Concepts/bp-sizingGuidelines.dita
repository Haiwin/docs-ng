<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic xml:lang="en-us" id="topic13047"><title>Sizing guidelines</title><body><p>Here are the primary considerations when sizing your Couchbase Server cluster:</p><ul>
<li><p>How many nodes do I need?</p></li>
<li><p>How large (RAM, CPU, disk space) should those nodes be?</p></li>
</ul><p>To answer the first question, consider following factors:</p><ul>
<li><p>RAM</p></li>
<li><p>Disk throughput and sizing</p></li>
<li><p>Network bandwidth</p></li>
<li><p>Data distribution and safety</p></li>
</ul><p>Due to the in-memory nature of Couchbase Server, RAM is usually the determining
factor for sizing. But ultimately, how you choose your primary factor will
depend on the data set and information that you are storing.</p><ul>
<li><p>If you have a very small data set that gets a very high load, you’ll need to
 base your size more off of network bandwidth than RAM.</p></li>
<li><p>If you have a very high write rate, you’ll need more nodes to support the disk
 throughput needed to persist all that data (and likely more RAM to buffer the
 incoming writes).</p></li>
<li><p>Even with a very small dataset under low load, you may want three nodes for
 proper distribution and safety.</p></li>
</ul><p>With Couchbase Server, you can increase the capacity of your cluster (RAM, Disk,
CPU, or network) by increasing the number of nodes within your cluster, since
each limit will be increased linearly as the cluster size is increased.</p><p><!--Removed anchor point couchbase-bestpractice-sizing-ram--></p><section><title>RAM sizing</title><p>RAM is usually the most critical sizing parameter. It’s also the one that can
have the biggest impact on performance and stability.</p><p><!--Removed anchor point couchbase-bestpractice-sizing-ram-workingset--></p></section><section><title>Working set</title><p>The working set is the data that
the client application actively uses at any point in time. Ideally, all of the
working set lives in memory. This impacts how much memory is needed.</p><p><!--Removed anchor point couchbase-bestpractice-sizing-ram-memoryquota--></p></section><section><title>Memory quota</title><p>It is very important that your Couchbase cluster’s size corresponds to the
working set size and total data you expect.</p><p>The goal is to size the available RAM to Couchbase so that all your document
IDs, the document ID meta data, and the working set values fit. The memory
should rest just below the point at which Couchbase will start evicting values
to disk (the High Water Mark).</p><p>How much memory and disk space per node you will need depends on several
different variables, which are defined below:</p><p><b>Calculations are per bucket</b></p><p>The calculations below are per-bucket calculations. The calculations need to be
summed up across all buckets. If all your buckets have the same configuration,
you can treat your total data as a single bucket. There is no per-bucket
overhead that needs to be considered.</p><p><!--Removed anchor point couchbase-bestpractice-sizing-ram-inputvars--></p><table><tgroup cols="2"><colspec colname="col1"/><colspec colname="col2"/><thead><row>
	<entry>Variable</entry>
	<entry>Description</entry>
</row></thead><tbody><row>
	<entry>documents_num</entry>
	<entry>The total number of documents you expect in your working set</entry>
</row><row>
	<entry>ID_size</entry>
	<entry>The average size of document IDs</entry>
</row><row>
	<entry>value_size</entry>
	<entry>The average size of values</entry>
</row><row>
	<entry>number_of_replicas</entry>
	<entry>The number of copies of the original data you want to keep</entry>
</row><row>
	<entry>working_set_percentage</entry>
	<entry>The percentage of your data you want in memory</entry>
</row><row>
	<entry>per_node_ram_quota</entry>
	<entry>How much RAM can be assigned to Couchbase </entry>
</row></tbody></tgroup></table><p>Use the following items to calculate how much memory you need:</p><p><!--Removed anchor point couchbase-bestpractice-sizing-ram-constants--></p><table><tgroup cols="2"><colspec colname="col1"/><colspec colname="col2"/><thead><row>
	<entry>Constant</entry>
	<entry>Description</entry>
</row></thead><tbody><row>
	<entry>Metadata per document (metadata_per_document)</entry>
	<entry>This is the amount of memory that Couchbase needs to store metadata per document. Metadata uses 56 bytes. All the metadata needs to live in memory while a node is running and serving data.</entry>
</row><row>
	<entry>SSD or Spinning</entry>
	<entry>SSDs give better I/O performance.</entry>
</row><row>
	<entry>headroom</entry>
	<entry>The cluster needs additional overhead to store metadata. That space is called the headroom. This requires approximately 25–30% more space than the raw RAM requirements for your dataset. Since SSDs are faster than spinning (traditional) hard disks, you should set aside 25% of memory for SSDs and 30% of memory for spinning hard disks.</entry>
</row><row>
	<entry>High Water Mark (high_water_mark)</entry>
	<entry>By default, the high water mark for a node’s RAM is set at 85%. </entry>
</row></tbody></tgroup></table><p>This is a rough guideline to size your cluster:</p><p><!--Removed anchor point couchbase-bestpractice-sizing-ram-calculations--></p><table><tgroup cols="2"><colspec colname="col1"/><colspec colname="col2"/><thead><row>
	<entry>Variable</entry>
	<entry>Calculation</entry>
</row></thead><tbody><row>
	<entry>no_of_copies</entry>
	<entry><codeph>1 + number_of_replicas</codeph></entry>
</row><row>
	<entry>total_metadata All the documents need to live in the memory.</entry>
	<entry><codeph>(documents_num) * (metadata_per_document + ID_size) * (no_of_copies)</codeph></entry>
</row><row>
	<entry>total_dataset</entry>
	<entry><codeph>(documents_num) * (value_size) * (no_of_copies)</codeph></entry>
</row><row>
	<entry>working_set</entry>
	<entry><codeph>total_dataset * (working_set_percentage)</codeph></entry>
</row><row>
	<entry>Cluster RAM quota required</entry>
	<entry><codeph>(total_metadata + working_set) * (1 + headroom) / (high_water_mark)</codeph></entry>
</row><row>
	<entry>number of nodes</entry>
	<entry><codeph>Cluster RAM quota required / per_node_ram_quota</codeph> </entry>
</row></tbody></tgroup></table><p>You will need at least the number of replicas + 1 nodes regardless of your data
size.</p><p>Here is a sample sizing calculation:</p><p><!--Removed anchor point couchbase-bestpractice-sizing-ram-sample-inputvars--></p><table><tgroup cols="2"><colspec colname="col1"/><colspec colname="col2"/><thead><row>
	<entry>Input Variable</entry>
	<entry>value</entry>
</row></thead><tbody><row>
	<entry>documents_num</entry>
	<entry>1,000,000</entry>
</row><row>
	<entry>ID_size</entry>
	<entry>100</entry>
</row><row>
	<entry>value_size</entry>
	<entry>10,000</entry>
</row><row>
	<entry>number_of_replicas</entry>
	<entry>1</entry>
</row><row>
	<entry>working_set_percentage</entry>
	<entry>20% </entry>
</row></tbody></tgroup></table><p><!--Removed anchor point couchbase-bestpractice-sizing-ram-sample-constants--></p><table><tgroup cols="2"><colspec colname="col1"/><colspec colname="col2"/><thead><row>
	<entry>Constants</entry>
	<entry>value</entry>
</row></thead><tbody><row>
	<entry>Type of Storage</entry>
	<entry>SSD</entry>
</row><row>
	<entry>overhead_percentage</entry>
	<entry>25%</entry>
</row><row>
	<entry>metadata_per_document</entry>
	<entry>56 for 2.1 and higher, 64 for 2.0.x</entry>
</row><row>
	<entry>high_water_mark</entry>
	<entry>85% </entry>
</row></tbody></tgroup></table><p><!--Removed anchor point couchbase-bestpractice-sizing-ram-sample-vars--></p><table><tgroup cols="2"><colspec colname="col1"/><colspec colname="col2"/><thead><row>
	<entry>Variable</entry>
	<entry>Calculation</entry>
</row></thead><tbody><row>
	<entry>no_of_copies</entry>
	<entry>= 1 for original and 1 for replica</entry>
</row><row>
	<entry>total_metadata</entry>
	<entry>= 1,000,000 * (100 + 56) * (2) = 312,000,000</entry>
</row><row>
	<entry>total_dataset</entry>
	<entry>= 1,000,000 * (10,000) * (2) = 20,000,000,000</entry>
</row><row>
	<entry>working_set</entry>
	<entry>= 20,000,000,000 * (0.2) = 4,000,000,000</entry>
</row><row>
	<entry>Cluster RAM quota required</entry>
	<entry>= (440,000,000 + 4,000,000,000) * (1+0.25)/(0.7) = 7,928,000,000</entry>
</row></tbody></tgroup></table><p>For example, if you have 8GB machines and you want to use 6 GB for Couchbase…</p><codeblock><codeph>number of nodes =
    Cluster RAM quota required/per_node_ram_quota =
    7.9 GB/6GB = 1.3 or 2 nodes
</codeph></codeblock><p><b>RAM quota</b></p><p>You will not be able to allocate all your machine RAM to the
per_node_ram_quota as there may be other programs running on your machine.</p><p><!--Removed anchor point couchbase-bestpractice-sizing-disk--></p></section><section><title>Disk throughput and sizing</title><p>Couchbase Server decouples RAM from the I/O layer.
Decoupling allows high scaling at very low and consistent latencies and enables
very high write loads without affecting client application performance. </p><p>Couchbase Server implements an append-only format and a built-in
automatic compaction process. Previously, in Couchbase Server 1.8.x,
an “in-place-update” disk format was implemented, however,
this implementation occasionally produced a performance penalty due to fragmentation of the
on-disk files under workloads with frequent updates/deletes. </p><p>The requirements of your disk subsystem are broken down into two components:
size and IO. </p><p><b>Size</b> </p><p>Disk size requirements are impacted by the Couchbase file write format, append-only, and the built-in automatic compaction process. Append-only format means that every write (insert/update/delete) creates a new entry in the file(s).</p><p>The required disk size increases from the update and delete workload and then shrinks as the automatic compaction process runs. The size increases because of the data expansion rather than the actual data using more disk space. Heavier update and delete workloads increases the size more dramatically than heavy insert and read workloads.</p><p>Size recommendations are available for key-value data only. If views and indexes or XDCR are implemented, contact Couchbase support for analysis and recommendations.</p><p><b>Key-value data only</b> — Depending on the workload, the required disk size is <b>2–3x</b> your total dataset size (active and replica data combined). </p><p>Important</p><p>The disk size requirement of 2-3x your total dataset size applies to key-value data only and does not take into account other data formats and the use of views and indexes or XDCR. 
</p><p><b>IO</b> </p><p>IO is a combination of the sustained write rate, the need for compacting the database files, and anything else that requires disk access. Couchbase Server automatically buffers writes to the database in RAM and eventually persists them to disk. Because of this, the software can accommodate much higher write rates than a disk is able to handle. However, sustaining these writes eventually requires enough IO to get it all down to disk. </p><p>To manage IO, configure the thresholds and schedule when the compaction process kicks in or doesn’t kick in keeping in mind that the successful completion of compaction is critical to keeping the disk size in check. Disk size and disk IO become critical to size correctly when using views and indexes and cross-data center replication (XDCR) as well as taking backup and anything else outside of Couchbase that need space or is accessing the disk. </p><p>Best practice</p><p> 
Use the available configuration options to separate data files, indexes and the installation/config directories on separate drives/devices to ensure that IO and space are allocated effectively. 
</p><p><!--Removed anchor point couchbase-bestpractice-sizing-network--></p></section><section><title>Network bandwidth</title><p>Network bandwidth is not normally a significant factor to consider for cluster
sizing. However, clients require network bandwidth to access information in the
cluster. Nodes also need network bandwidth to exchange information (node to
node).</p><p>In general you can calculate your network bandwidth requirements using this
formula:</p><codeblock><codeph>Bandwidth = (operations per second * item size) +
    overhead for rebalancing
</codeph></codeblock><p>And you can calculate the <codeph>operations per second</codeph> with this formula:</p><codeblock><codeph>Operations per second = Application reads +
    (Application writes * Replica copies)
</codeph></codeblock><p><!--Removed anchor point couchbase-bestpractice-sizing-datasafety--></p></section><section><title>Data safety</title><p>Make sure you have enough nodes (and the right configuration) in your cluster to
keep your data safe. There are two areas to keep in mind: how you distribute
data across nodes and how many replicas you store across your cluster.</p><p><!--Removed anchor point couchbase-bestpractice-sizing-datadistribution--></p></section><section><title>Data distribution</title><p>Basically, more nodes are better than less. If you only have two nodes, your
data will be split across the two nodes, half and half. This means that half of
your dataset will be “impacted” if one goes away. On the other hand, with ten
nodes, only 10% of the dataset will be “impacted” if one goes away. Even with
automatic failover, there will still be some period of time when data is
unavailable if nodes fail. This can be mitigated by having more nodes.</p><p>After a failover, the cluster will need to take on an extra load. The question
is - how heavy is that extra load and are you prepared for it? Again, with only
two nodes, each one needs to be ready to handle the entire load. With ten, each
node only needs to be able to take on an extra tenth of the workload should one
fail.</p><p>While two nodes does provide a minimal level of redundancy, we recommend that
you always use at least three nodes.</p><p><!--Removed anchor point couchbase-bestpractice-sizing-replication--></p></section><section><title>Replication</title><p>Couchbase Server allows you to configure up to three replicas (creating four
copies of the dataset). In the event of a failure, you can only “failover”
(either manually or automatically) as many nodes as you have replicas. Here are
examples:</p><ul>
<li><p>In a five node cluster with one replica, if one node goes down, you can fail it
 over. If a second node goes down, you no longer have enough replica copies to
 fail over to and will have to go through a slower process to recover.</p></li>
<li><p>In a five node cluster with two replicas, if one node goes down, you can fail it
 over. If a second node goes down, you can fail it over as well. Should a third
 one go down, you now no longer have replicas to fail over.</p></li>
</ul><p>After a node goes down and is failed over, try to replace that node as soon as
possible and rebalance. The rebalance will recreate the replica copies (if you
still have enough nodes to do so).</p><p>As a rule of thumb, we recommend that you configure the following:</p><ul>
<li><p>One replica for up to five nodes</p></li>
<li><p>One or two replicas for five to ten nodes</p></li>
<li><p>One, two, or three replicas for over ten nodes</p></li>
</ul><p>While there may be variations to this, there are diminishing returns from having
more replicas in smaller clusters.</p><p><!--Removed anchor point couchbase-bestpractice-sizing-hardware--></p></section><section><title>Hardware requirements</title><p>In general, Couchbase Server has very low hardware requirements and is designed
to be run on commodity or virtualized systems. However, as a rough guide to the
primary concerns for your servers, here is what we recommend:</p><ul>
<li><p>RAM: This is your primary consideration. We use RAM to store active items, and
 that is the key reason Couchbase Server has such low latency.</p></li>
<li><p>CPU: Couchbase Server has very low CPU requirements. The server is
 multi-threaded and therefore benefits from a multi-core system. We recommend
 machines with at least four or eight physical cores.</p></li>
<li><p>Disk: By decoupling the RAM from the I/O layer, Couchbase Server can support
 low-performance disks better than other databases. As a best practice we
 recommend that you have a separate devices for server install, data directories,
 and index directories.</p></li>
</ul><p>Known working configurations include SAN, SAS, SATA, SSD, and EBS, with the
 following recommendations:</p><codeblock><codeph>* SSDs have been shown to provide a great performance boost both in terms of
  draining the write queue and also in restoring data from disk (either on
  cold-boot or for purposes of rebalancing).

* RAID generally provides better throughput and reliability.

* Striping across EBS volumes (in Amazon EC2) has been shown to increase
  throughput.
</codeph></codeblock><ul>
<li>Network: Most configurations will work with Gigabit Ethernet interfaces. Faster
 solutions such as 10GBit and Infiniband will provide spare capacity.</li>
</ul><p><!--Removed anchor point couchbase-bestpractice-sizing-cloud--></p></section><section><title>Considerations for Cloud environments (i.e. Amazon EC2)</title><p>Due to the unreliability and general lack of consistent I/O performance in cloud
environments, we highly recommend lowering the per-node RAM footprint and
increasing the number of nodes. This will give better disk throughput as well as
improve rebalancing since each node will have to store (and therefore transmit)
less data. By distributing the data further, it lessens the impact of losing a
single node (which could be fairly common).</p><p>Read about best practices with the cloud in <xref href="#topic13047/couchbase-bestpractice-cloud">Using Couchbase in the
Cloud</xref>.</p></section></body></topic>